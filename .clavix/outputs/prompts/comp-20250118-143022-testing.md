---
id: comp-20250118-143022-testing
depthUsed: comprehensive
timestamp: 2025-01-18T14:30:22Z
executed: true
executedAt: 2025-01-18T15:30:00Z
phase4CompletedAt: 2025-01-18T16:00:00Z
originalPrompt: Corre todos los tests, los que fallen crea un plan para arreglarlos. Si los tests pasan todos quiero que revises la cobertura que tienene y si respetan la estructura de tests propuesta para el sistema en @docs/testing/guia-tests.md
executionResult: |
  Tests ejecutados: 168 unit (163 pass, 5 fail), 3 integration (require DB), 143 E2E (require app)
  Reporte de fallos: .clavix/outputs/test-failures-report.md
  Phase 4 - Estructura: .clavix/outputs/phase4-structure-validation-report.md
  Score estructura: 89% ✅ APROBADO
---

# Optimized Prompt

## Objective: Ejecutar suite de tests completa, analizar fallos, verificar cobertura y validar estructura según guía

### Contexto del Proyecto
- **Sistema**: NexoPOS - Sistema de Gestión POS
- **Stack**: NestJS (Backend) + React/Vite (Frontend) + PostgreSQL + Playwright
- **Guía de referencia**: `docs/testing/guia-tests.md`
- **Workspace principal**: `c:\Users\agust\Desktop\Proyectos\sistema-gestion`

## Phase 1: Ejecutar Tests

### Backend Tests
```powershell
# Ejecutar todos los tests unitarios del backend
cd apps/backend
npm run test:unit

# Ejecutar tests de integración
npm run test:integration

# Ejecutar todos los tests con coverage
npm run test:all
```

### Frontend E2E Tests
```powershell
# Ejecutar tests E2E del frontend
cd apps/frontend
npm run test:e2e
```

## Phase 2: Análisis de Fallos

Si algún test falla:
1. Identificar el test específico que falló
2. Leer el archivo de test y el error completo
3. Analizar la causa raíz:
   - Error de configuración (mock, setup)
   - Error de lógica (assertion incorrecta)
   - Error de ambiente (BD no disponible, dependencias faltantes)
   - Cambio en el código que rompió el test
4. Crear un plan de corrección con:
   - Descripción del problema
   - Archivo(s) a modificar
   - Cambios necesarios
   - Tests de verificación

## Phase 3: Verificación de Cobertura

### Objetivos de cobertura mínima
- Unit tests: >70% coverage en código crítico
- Integration tests: Cubrir flujos principales
- E2E tests: Cubrir happy paths de módulos core

### Comandos de coverage
```powershell
# Backend con reporte detallado
cd apps/backend
npm run test:all -- --coverage --verbose

# Ver reporte HTML (si está configurado)
# Abrir coverage/index.html en navegador
```

## Phase 4: Validación de Estructura

Verificar que los tests siguen las convenciones de `docs/testing/guia-tests.md`:

### Convenciones a validar
- [ ] Unit tests: `*.spec.ts` junto al código fuente (`apps/backend/src/**/*.spec.ts`)
- [ ] Integration tests: `*.integration.spec.ts` en `apps/backend/test/integration/`
- [ ] E2E tests: `*.spec.ts` en `apps/frontend/e2e/tests/`
- [ ] Factories: `*.factory.ts` en `apps/backend/test/factories/`
- [ ] Naming: Tests nombrados como `debe [acción] cuando [condición]`
- [ ] Estructura: `describe/it` con `beforeEach/beforeAll/afterEach/afterAll`

### Validar específicamente
1. Tests unitarios no deben probar I/O (BD, HTTP)
2. Tests de integración deben usar BD real o contenedores
3. Tests E2E deben probar flujos completos del usuario
4. Cada test debe ser independiente (sin dependencias de orden)

## Expected Output

### Si todos los tests pasan
- Resumen de tests ejecutados (cantidad de specs, cantidad de tests)
- Métricas de cobertura (porcentajes por módulo)
- Validación de estructura (✅ o ❌ por cada convención)
- Recomendaciones de mejora si aplica

### Si hay fallos
- Lista de tests fallidos con error completo
- Plan detallado de corrección para cada test fallido
- Archivos específicos a modificar con cambios propuestos

## Quality Scores
- **Clarity**: 85%
- **Efficiency**: 90%
- **Structure**: 80%
- **Completeness**: 70% → 95%
- **Actionability**: 75% → 95%
- **Specificity**: 85%
- **Overall**: 82% → 92%

## Alternative Approaches

### 1. Enfoque Iterativo (Ejecutar por tipo)
Ejecutar tests por capa (unit → integration → E2E) y corregir fallos antes de pasar a la siguiente. Mejor para identificar problemas temprano.

### 2. Enfoque Completo (Todo de una vez)
Ejecutar toda la suite y collect todos los fallos antes de corregir. Mejor para tener visión completa pero puede ser abrumador.

### 3. Enfoque Crítico (Priorizar módulos core)
Enfocarse primero en módulos críticos (ventas, caja, productos) antes que módulos secundarios. Mejor para sistemas grandes con tiempo limitado.

## Validation Checklist

### Ejecución
- [ ] Todos los comandos de test ejecutaron sin errores de sintaxis
- [ ] Tests unitarios ejecutados
- [ ] Tests de integración ejecutados (si BD disponible)
- [ ] Tests E2E ejecutados (si aplicación está corriendo)

### Análisis de fallos
- [ ] Cada test fallido fue analizado individualmente
- [ ] Causa raíz identificada para cada fallo
- [ ] Plan de corrección incluye archivos específicos y cambios

### Cobertura
- [ ] Métricas de coverage recopiladas
- [ ] Módulos con baja cobertura identificados
- [ ] Umbral mínimo del 70% validado (o documentado si no se cumple)

### Estructura
- [ ] Ubicación de archivos valida convenciones de la guía
- [ ] Naming conventions seguidas
- [ ] Aislamiento entre tests verificado

## Edge Cases to Considerar

- **BD no disponible**: Tests de integración fallan por PostgreSQL no corriendo
- **Aplicación no iniciada**: Tests E2E fallan porque el frontend no está corriendo
- **Tests con datos stale**: Tests que dependen de datos semilla que fueron modificados
- **Tests con timeouts**: Tests que pasan localmente pero fallan en CI por ser más lentos
- **Credenciales inválidas**: Tests E2E fallan porque las credenciales por defecto cambiaron
- **Cambio de API**: Tests fallan porque el código cambió pero los tests no se actualizaron
- **Tests frágiles**: Tests que dependen del orden de ejecución o comparten estado

## What Could Go Wrong

- **Tests fallan masivamente**: Puede indicar problema de configuración o ambiente, no del código
- **Coverage engañosa**: Alto porcentaje pero solo por líneas triviales sin asserts reales
- **Tests muy lentos**: Tests que toman mucho tiempo pueden ser señal de mal diseño
- **Tests intermitentes**: Tests que fallan aleatoriamente indican race conditions o estado compartido
- **Sobre-testing**: Tests de implementación detalle que rompen con cada refactor

## Original Prompt
```
Corre todos los tests, los que fallen crea un plan para arreglarlos. Si los tests pasan todos quiero que revises la cobertura que tienene y si respetan la estructura de tests propuesta para el sistema en @docs/testing/guia-tests.md
```
